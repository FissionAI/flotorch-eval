{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install flotorch-eval crewai plotly opentelemetry-api opentelemetry-sdk pandas ragas duckduckgo-search openlit langchain_aws\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter\n",
        "\n",
        "\n",
        "# Create an in-memory span exporter\n",
        "memory_exporter = InMemorySpanExporter()\n",
        "span_processor = SimpleSpanProcessor(memory_exporter)\n",
        "\n",
        "# Set up the tracer provider and add the span processor\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(span_processor)\n",
        "trace.set_tracer_provider(tracer_provider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 325,\n",
            "                                                \"time_unix_nano\": 1749428307673539000,\n",
            "                                                \"span_id\": 10425311303977551225,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            },\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 1376,\n",
            "                                                \"time_unix_nano\": 1749428309379228000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 1.0240778923034668,\n",
            "                                                \"time_unix_nano\": 1749428309379268000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 0.641761064529419,\n",
            "                                                \"time_unix_nano\": 1749428307673633000,\n",
            "                                                \"span_id\": 10425311303977551225,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            },\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 1.0240778923034668,\n",
            "                                                \"time_unix_nano\": 1749428309379278000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 1,\n",
            "                                                \"time_unix_nano\": 1749428309379287000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 20,\n",
            "                                                \"time_unix_nano\": 1749428307673667000,\n",
            "                                                \"span_id\": 10425311303977551225,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 1269,\n",
            "                                                \"time_unix_nano\": 1749428309379308000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428364145252000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": [\n",
            "                                            {\n",
            "                                                \"filtered_attributes\": {},\n",
            "                                                \"value\": 0,\n",
            "                                                \"time_unix_nano\": 1749428309379313000,\n",
            "                                                \"span_id\": 5772935052406610711,\n",
            "                                                \"trace_id\": 120435592340411138243212892409570918823\n",
            "                                            }\n",
            "                                        ]\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428424155460000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428484164154000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428544169737000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428604176434000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428664186075000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428724196789000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"resource_metrics\": [\n",
            "        {\n",
            "            \"resource\": {\n",
            "                \"attributes\": {\n",
            "                    \"telemetry.sdk.language\": \"python\",\n",
            "                    \"telemetry.sdk.name\": \"openlit\",\n",
            "                    \"telemetry.sdk.version\": \"1.34.0\",\n",
            "                    \"service.name\": \"default\",\n",
            "                    \"deployment.environment\": \"default\"\n",
            "                },\n",
            "                \"schema_url\": \"\"\n",
            "            },\n",
            "            \"scope_metrics\": [\n",
            "                {\n",
            "                    \"scope\": {\n",
            "                        \"name\": \"openlit.otel.metrics\",\n",
            "                        \"version\": \"0.1.0\",\n",
            "                        \"schema_url\": \"\",\n",
            "                        \"attributes\": null\n",
            "                    },\n",
            "                    \"metrics\": [\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.token.usage\",\n",
            "                            \"description\": \"Measures number of input and output tokens used\",\n",
            "                            \"unit\": \"{token}\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673595000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1701,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            1,\n",
            "                                            4,\n",
            "                                            16,\n",
            "                                            64,\n",
            "                                            256,\n",
            "                                            1024,\n",
            "                                            4096,\n",
            "                                            16384,\n",
            "                                            65536,\n",
            "                                            262144,\n",
            "                                            1048576,\n",
            "                                            4194304,\n",
            "                                            16777216,\n",
            "                                            67108864\n",
            "                                        ],\n",
            "                                        \"min\": 325,\n",
            "                                        \"max\": 1376,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.client.operation.duration\",\n",
            "                            \"description\": \"GenAI operation duration\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673624000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.08,\n",
            "                                            0.16,\n",
            "                                            0.32,\n",
            "                                            0.64,\n",
            "                                            1.28,\n",
            "                                            2.56,\n",
            "                                            5.12,\n",
            "                                            10.24,\n",
            "                                            20.48,\n",
            "                                            40.96,\n",
            "                                            81.92\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
            "                            \"description\": \"Time to generate first token for successful responses\",\n",
            "                            \"unit\": \"s\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673639000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 1.6658389568328857,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            1,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.001,\n",
            "                                            0.005,\n",
            "                                            0.01,\n",
            "                                            0.02,\n",
            "                                            0.04,\n",
            "                                            0.06,\n",
            "                                            0.08,\n",
            "                                            0.1,\n",
            "                                            0.25,\n",
            "                                            0.5,\n",
            "                                            0.75,\n",
            "                                            1.0,\n",
            "                                            2.5,\n",
            "                                            5.0,\n",
            "                                            7.5,\n",
            "                                            10.0\n",
            "                                        ],\n",
            "                                        \"min\": 0.641761064529419,\n",
            "                                        \"max\": 1.0240778923034668,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.total.requests\",\n",
            "                            \"description\": \"Number of requests to GenAI\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673656000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"value\": 2,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
            "                            \"description\": \"Number of completion tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673676000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"value\": 127,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
            "                            \"description\": \"Number of prompt tokens processed.\",\n",
            "                            \"unit\": \"1\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673688000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"value\": 1574,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2,\n",
            "                                \"is_monotonic\": true\n",
            "                            }\n",
            "                        },\n",
            "                        {\n",
            "                            \"name\": \"gen_ai.usage.cost\",\n",
            "                            \"description\": \"The distribution of GenAI request costs.\",\n",
            "                            \"unit\": \"USD\",\n",
            "                            \"data\": {\n",
            "                                \"data_points\": [\n",
            "                                    {\n",
            "                                        \"attributes\": {\n",
            "                                            \"telemetry.sdk.name\": \"openlit\",\n",
            "                                            \"service.name\": \"default\",\n",
            "                                            \"deployment.environment\": \"default\",\n",
            "                                            \"gen_ai.operation.name\": \"chat\",\n",
            "                                            \"gen_ai.system\": \"litellm\",\n",
            "                                            \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "                                            \"server.address\": \"NOT_FOUND\",\n",
            "                                            \"server.port\": \"NOT_FOUND\",\n",
            "                                            \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\"\n",
            "                                        },\n",
            "                                        \"start_time_unix_nano\": 1749428307673699000,\n",
            "                                        \"time_unix_nano\": 1749428784202371000,\n",
            "                                        \"count\": 2,\n",
            "                                        \"sum\": 0,\n",
            "                                        \"bucket_counts\": [\n",
            "                                            2,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0,\n",
            "                                            0\n",
            "                                        ],\n",
            "                                        \"explicit_bounds\": [\n",
            "                                            0.0,\n",
            "                                            5.0,\n",
            "                                            10.0,\n",
            "                                            25.0,\n",
            "                                            50.0,\n",
            "                                            75.0,\n",
            "                                            100.0,\n",
            "                                            250.0,\n",
            "                                            500.0,\n",
            "                                            750.0,\n",
            "                                            1000.0,\n",
            "                                            2500.0,\n",
            "                                            5000.0,\n",
            "                                            7500.0,\n",
            "                                            10000.0\n",
            "                                        ],\n",
            "                                        \"min\": 0,\n",
            "                                        \"max\": 0,\n",
            "                                        \"exemplars\": []\n",
            "                                    }\n",
            "                                ],\n",
            "                                \"aggregation_temporality\": 2\n",
            "                            }\n",
            "                        }\n",
            "                    ],\n",
            "                    \"schema_url\": \"\"\n",
            "                }\n",
            "            ],\n",
            "            \"schema_url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openlit\n",
        "\n",
        "# Initialize OpenLit - this will automatically instrument CrewAI when it's imported\n",
        "openlit.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"name\": \"Crew Created\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xff2f904880d407a9cd054b7c8b449d3a\",\n",
            "        \"span_id\": \"0x551c67301da45cdd\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-06-09T00:18:27.025602Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:27.026344Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crewai_version\": \"0.126.0\",\n",
            "        \"python_version\": \"3.13.0\",\n",
            "        \"crew_key\": \"a7f38a97312c2a08d7161334f446c413\",\n",
            "        \"crew_id\": \"dbb3f4b1-952a-41d9-8579-65b940961723\",\n",
            "        \"crew_process\": \"sequential\",\n",
            "        \"crew_memory\": false,\n",
            "        \"crew_number_of_tasks\": 1,\n",
            "        \"crew_number_of_agents\": 1,\n",
            "        \"crew_fingerprint\": \"701b4b29-f5d1-498e-95c7-7afccf4877cb\",\n",
            "        \"crew_fingerprint_created_at\": \"2025-06-08T17:18:27.024628\",\n",
            "        \"crew_agents\": \"[{\\\"key\\\": \\\"18e63413ba6e2f4d81ec74e7660d93d9\\\", \\\"id\\\": \\\"6cf70835-7ba4-4304-8f19-8b478c4d0147\\\", \\\"role\\\": \\\"Writer\\\", \\\"verbose?\\\": false, \\\"max_iter\\\": 25, \\\"max_rpm\\\": null, \\\"function_calling_llm\\\": \\\"\\\", \\\"llm\\\": \\\"bedrock/us.amazon.nova-pro-v1:0\\\", \\\"delegation_enabled?\\\": false, \\\"allow_code_execution?\\\": false, \\\"max_retry_limit\\\": 2, \\\"tools_names\\\": [\\\"duckduckgosearch\\\"]}]\",\n",
            "        \"crew_tasks\": \"[{\\\"key\\\": \\\"a4e196e286182fc8683d3e8a3ea41110\\\", \\\"id\\\": \\\"70d9cbd8-2c44-4585-8407-5dc3a341e11f\\\", \\\"async_execution?\\\": false, \\\"human_input?\\\": false, \\\"agent_role\\\": \\\"Writer\\\", \\\"agent_key\\\": \\\"18e63413ba6e2f4d81ec74e7660d93d9\\\", \\\"tools_names\\\": [\\\"duckduckgosearch\\\"]}]\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"Task Created\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0xeb4b714c2b5de034\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0x4e38a79b9b05eb45\",\n",
            "    \"start_time\": \"2025-06-09T00:18:27.027989Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:27.028029Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crew_key\": \"a7f38a97312c2a08d7161334f446c413\",\n",
            "        \"crew_id\": \"dbb3f4b1-952a-41d9-8579-65b940961723\",\n",
            "        \"task_key\": \"a4e196e286182fc8683d3e8a3ea41110\",\n",
            "        \"task_id\": \"70d9cbd8-2c44-4585-8407-5dc3a341e11f\",\n",
            "        \"crew_fingerprint\": \"701b4b29-f5d1-498e-95c7-7afccf4877cb\",\n",
            "        \"task_fingerprint\": \"9c3c5c11-9bb8-460e-b493-3bb6ed3e22e7\",\n",
            "        \"task_fingerprint_created_at\": \"2025-06-08T17:18:27.024547\",\n",
            "        \"agent_fingerprint\": \"411151d5-c538-49e1-9d2a-13698d9fa7c2\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"chat bedrock/us.amazon.nova-pro-v1:0\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0x90ae256532724579\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xcf884b2d17cb1cee\",\n",
            "    \"start_time\": \"2025-06-09T00:18:27.031697Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:27.673708Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.operation.name\": \"chat\",\n",
            "        \"gen_ai.system\": \"litellm\",\n",
            "        \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.request.seed\": \"\",\n",
            "        \"server.port\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.frequency_penalty\": 0.0,\n",
            "        \"gen_ai.request.max_tokens\": 4096,\n",
            "        \"gen_ai.request.presence_penalty\": 0.0,\n",
            "        \"gen_ai.request.stop_sequences\": [\n",
            "            \"\\nObservation:\"\n",
            "        ],\n",
            "        \"gen_ai.request.temperature\": 0.7,\n",
            "        \"gen_ai.request.top_p\": 1.0,\n",
            "        \"gen_ai.response.id\": \"chatcmpl-756b4211-10ab-41c1-84d4-93ffdc57cbf4\",\n",
            "        \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.usage.input_tokens\": 305,\n",
            "        \"gen_ai.usage.output_tokens\": 20,\n",
            "        \"server.address\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.service_tier\": \"auto\",\n",
            "        \"gen_ai.response.system_fingerprint\": \"None\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"gen_ai.request.user\": \"\",\n",
            "        \"gen_ai.request.is_stream\": false,\n",
            "        \"gen_ai.usage.total_tokens\": 325,\n",
            "        \"gen_ai.usage.cost\": 0,\n",
            "        \"gen_ai.server.time_to_first_token\": 0.641761064529419,\n",
            "        \"gen_ai.sdk.version\": \"1.68.0\",\n",
            "        \"gen_ai.response.finish_reasons\": [\n",
            "            \"stop\"\n",
            "        ],\n",
            "        \"gen_ai.output.type\": \"text\"\n",
            "    },\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.prompt\",\n",
            "            \"timestamp\": \"2025-06-09T00:18:27.673517Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.prompt\": \"system: You are Writer. You're an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it's written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \\\" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\"\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.completion\",\n",
            "            \"timestamp\": \"2025-06-09T00:18:27.673529Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.completion\": \"Action: DuckDuckGoSearch\\nAction Input: {\\\"search_query\\\": \\\"AWS Bedrock\\\"}\"\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"Tool Usage\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0x280d88e85cec8f10\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xcf884b2d17cb1cee\",\n",
            "    \"start_time\": \"2025-06-09T00:18:28.353627Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:28.354369Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crewai_version\": \"0.126.0\",\n",
            "        \"tool_name\": \"DuckDuckGoSearch\",\n",
            "        \"attempts\": 1\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"chat bedrock/us.amazon.nova-pro-v1:0\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0x501d95d80618db17\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xcf884b2d17cb1cee\",\n",
            "    \"start_time\": \"2025-06-09T00:18:28.355018Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:29.379326Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.operation.name\": \"chat\",\n",
            "        \"gen_ai.system\": \"litellm\",\n",
            "        \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.request.seed\": \"\",\n",
            "        \"server.port\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.frequency_penalty\": 0.0,\n",
            "        \"gen_ai.request.max_tokens\": 4096,\n",
            "        \"gen_ai.request.presence_penalty\": 0.0,\n",
            "        \"gen_ai.request.stop_sequences\": [\n",
            "            \"\\nObservation:\"\n",
            "        ],\n",
            "        \"gen_ai.request.temperature\": 0.7,\n",
            "        \"gen_ai.request.top_p\": 1.0,\n",
            "        \"gen_ai.response.id\": \"chatcmpl-3cfc7e80-adc2-4df1-9679-74f712d36b96\",\n",
            "        \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.usage.input_tokens\": 1269,\n",
            "        \"gen_ai.usage.output_tokens\": 107,\n",
            "        \"server.address\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.service_tier\": \"auto\",\n",
            "        \"gen_ai.response.system_fingerprint\": \"None\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"gen_ai.request.user\": \"\",\n",
            "        \"gen_ai.request.is_stream\": false,\n",
            "        \"gen_ai.usage.total_tokens\": 1376,\n",
            "        \"gen_ai.usage.cost\": 0,\n",
            "        \"gen_ai.server.time_to_first_token\": 1.0240778923034668,\n",
            "        \"gen_ai.sdk.version\": \"1.68.0\",\n",
            "        \"gen_ai.response.finish_reasons\": [\n",
            "            \"stop\"\n",
            "        ],\n",
            "        \"gen_ai.output.type\": \"text\"\n",
            "    },\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.prompt\",\n",
            "            \"timestamp\": \"2025-06-09T00:18:29.379199Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.prompt\": \"system: You are Writer. You're an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it's written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \\\" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\\nassistant: [{'title': 'Amazon Bedrock', 'href': 'https://aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models'}, {'title': 'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com', 'href': 'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html', 'body': 'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.'}, {'title': 'What is Amazon Bedrock? - GeeksforGeeks', 'href': 'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/', 'body': \\\"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we'll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\\\"}, {'title': 'Amazon Bedrock Documentation', 'href': 'https://docs.aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.'}, {'title': 'Amazon Bedrock Documentation - aws.amazon.com', 'href': 'https://aws.amazon.com/documentation-overview/bedrock/', 'body': 'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.'}]\\nassistant: Action: DuckDuckGoSearch\\nAction Input: {\\\"search_query\\\": \\\"AWS Bedrock\\\"}\\nObservation: [{'title': 'Amazon Bedrock', 'href': 'https://aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models'}, {'title': 'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com', 'href': 'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html', 'body': 'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.'}, {'title': 'What is Amazon Bedrock? - GeeksforGeeks', 'href': 'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/', 'body': \\\"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we'll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\\\"}, {'title': 'Amazon Bedrock Documentation', 'href': 'https://docs.aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.'}, {'title': 'Amazon Bedrock Documentation - aws.amazon.com', 'href': 'https://aws.amazon.com/documentation-overview/bedrock/', 'body': 'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.'}]\"\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.completion\",\n",
            "            \"timestamp\": \"2025-06-09T00:18:29.379212Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.completion\": \"\\n\\nThought: I now know the final answer\\nFinal Answer: Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"crewai.agent_execute_task\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0xcf884b2d17cb1cee\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0x4e38a79b9b05eb45\",\n",
            "    \"start_time\": \"2025-06-09T00:18:27.030751Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:29.380706Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.system\": \"crewai\",\n",
            "        \"gen_ai.operation.name\": \"agent\",\n",
            "        \"gen_ai.endpoint\": \"crewai.agent_execute_task\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"gen_ai.agent.id\": \"6cf70835-7ba4-4304-8f19-8b478c4d0147\",\n",
            "        \"gen_ai.agent.role\": \"Writer\",\n",
            "        \"gen_ai.agent.goal\": \"You make GenAI concepts understandable for newbies exploring GenAI on AWS\",\n",
            "        \"gen_ai.agent.context\": \"You're an expert in writing crisp summaries about GenAI on AWS.\",\n",
            "        \"gen_ai.agent.enable_cache\": \"True\",\n",
            "        \"gen_ai.agent.allow_delegation\": \"False\",\n",
            "        \"gen_ai.agent.allow_code_execution\": \"False\",\n",
            "        \"gen_ai.agent.max_retry_limit\": \"2\",\n",
            "        \"gen_ai.agent.tools\": \"[{\\\"name\\\": \\\"DuckDuckGoSearch\\\", \\\"description\\\": \\\"Tool Name: DuckDuckGoSearch\\\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\\\nTool Description: Search the web for information on a given topic\\\"}]\",\n",
            "        \"gen_ai.agent.tool_results\": \"[{'result': '[{\\\\'title\\\\': \\\\'Amazon Bedrock\\\\', \\\\'href\\\\': \\\\'https://aws.amazon.com/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models\\\\'}, {\\\\'title\\\\': \\\\'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com\\\\', \\\\'href\\\\': \\\\'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.\\\\'}, {\\\\'title\\\\': \\\\'What is Amazon Bedrock? - GeeksforGeeks\\\\', \\\\'href\\\\': \\\\'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/\\\\', \\\\'body\\\\': \\\"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we\\\\'ll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\\\"}, {\\\\'title\\\\': \\\\'Amazon Bedrock Documentation\\\\', \\\\'href\\\\': \\\\'https://docs.aws.amazon.com/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.\\\\'}, {\\\\'title\\\\': \\\\'Amazon Bedrock Documentation - aws.amazon.com\\\\', \\\\'href\\\\': \\\\'https://aws.amazon.com/documentation-overview/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.\\\\'}]', 'tool_name': 'DuckDuckGoSearch', 'tool_args': {'search_query': 'AWS Bedrock'}}]\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"crewai.task_execute_core\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x5a9b0d264fd003657e4d334e410601a7\",\n",
            "        \"span_id\": \"0x4e38a79b9b05eb45\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-06-09T00:18:27.027904Z\",\n",
            "    \"end_time\": \"2025-06-09T00:18:29.381414Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.system\": \"crewai\",\n",
            "        \"gen_ai.operation.name\": \"agent\",\n",
            "        \"gen_ai.endpoint\": \"crewai.task_execute_core\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"gen_ai.agent.task.id\": \"70d9cbd8-2c44-4585-8407-5dc3a341e11f\",\n",
            "        \"gen_ai.agent.task\": \"What is AWS Bedrock?\",\n",
            "        \"gen_ai.agent.expected_output\": \"Compose a short summary that includes the answer.\",\n",
            "        \"gen_ai.agent.actual_output\": \"Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\",\n",
            "        \"gen_ai.agent.human_input\": \"False\",\n",
            "        \"gen_ai.agent.task_associations\": \"{'Writer'}\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.0\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\n"
          ]
        }
      ],
      "source": [
        "from crewai.tools import tool\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "@tool('DuckDuckGoSearch')\n",
        "def search_tool(search_query: str):\n",
        "    \"\"\"Search the web for information on a given topic\"\"\"\n",
        "    return DDGS().text(search_query, max_results=5)\n",
        "\n",
        "@tool('SalesforceIntegration')\n",
        "def salesforce_tool(soql_query: str):\n",
        "    \"\"\"Call Salesforce API to get data\"\"\"\n",
        "    return \"Salesforce Integration\"\n",
        "\n",
        "from crewai import LLM\n",
        "\n",
        "model = LLM(\n",
        "    # model=\"sagemaker/INSERT ENDPOINT NAME\",\n",
        "    model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
        "    temperature=0.7, max_tokens=4*1024,\n",
        ")\n",
        "\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "\n",
        "writer = Agent(\n",
        "        role=\"Writer\",\n",
        "        goal=\"You make GenAI concepts understandable for newbies exploring GenAI on AWS\",\n",
        "        backstory=\"You're an expert in writing crisp summaries about GenAI on AWS.\",\n",
        "        tools=[search_tool],\n",
        "        llm=model\n",
        "    )\n",
        "\n",
        "task = Task(description=(\"What is {topic}?\"),\n",
        "            expected_output=(\"Compose a short summary that includes the answer.\"),\n",
        "            agent=writer)\n",
        "\n",
        "crew = Crew(\n",
        "  agents=[writer],\n",
        "  tasks=[task],\n",
        "  share_crew=False\n",
        ")\n",
        "\n",
        "result = crew.kickoff({\"topic\": \"AWS Bedrock\"})\n",
        "print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of spans: 7\n"
          ]
        }
      ],
      "source": [
        "spans = memory_exporter.get_finished_spans()\n",
        "\n",
        "print(\"Number of spans:\", len(spans))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nanda/Work/workshops/agents-workshop/agent_eval/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain_aws import ChatBedrockConverse\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "bedrock_model = ChatBedrockConverse(\n",
        "    region_name=\"us-east-1\",\n",
        "    endpoint_url=f\"https://bedrock-runtime.us-east-1.amazonaws.com\",\n",
        "    model_id=\"us.amazon.nova-micro-v1:0\"\n",
        ")\n",
        "\n",
        "llm = LangchainLLMWrapper(bedrock_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flotorch_eval.agent_eval.core.converter import TraceConverter\n",
        "\n",
        "def create_trajectory(spans):\n",
        "    converter = TraceConverter()\n",
        "    trajectory = converter.from_spans(spans)\n",
        "    return trajectory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Trajectory(trace_id='ff2f904880d407a9cd054b7c8b449d3a', messages=[Message(role='user', content='What is AWS Bedrock?', tool_calls=[], timestamp=datetime.datetime(2025, 6, 8, 17, 18, 27, 31697)), Message(role='assistant', content='Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.', tool_calls=[], timestamp=datetime.datetime(2025, 6, 8, 17, 18, 29, 379326))], spans=[Span(span_id='551c67301da45cdd', trace_id='ff2f904880d407a9cd054b7c8b449d3a', parent_id=None, name='Crew Created', start_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 25602), end_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 26344), attributes={'crewai_version': '0.126.0', 'python_version': '3.13.0', 'crew_key': 'a7f38a97312c2a08d7161334f446c413', 'crew_id': 'dbb3f4b1-952a-41d9-8579-65b940961723', 'crew_process': 'sequential', 'crew_memory': False, 'crew_number_of_tasks': 1, 'crew_number_of_agents': 1, 'crew_fingerprint': '701b4b29-f5d1-498e-95c7-7afccf4877cb', 'crew_fingerprint_created_at': '2025-06-08T17:18:27.024628', 'crew_agents': '[{\"key\": \"18e63413ba6e2f4d81ec74e7660d93d9\", \"id\": \"6cf70835-7ba4-4304-8f19-8b478c4d0147\", \"role\": \"Writer\", \"verbose?\": false, \"max_iter\": 25, \"max_rpm\": null, \"function_calling_llm\": \"\", \"llm\": \"bedrock/us.amazon.nova-pro-v1:0\", \"delegation_enabled?\": false, \"allow_code_execution?\": false, \"max_retry_limit\": 2, \"tools_names\": [\"duckduckgosearch\"]}]', 'crew_tasks': '[{\"key\": \"a4e196e286182fc8683d3e8a3ea41110\", \"id\": \"70d9cbd8-2c44-4585-8407-5dc3a341e11f\", \"async_execution?\": false, \"human_input?\": false, \"agent_role\": \"Writer\", \"agent_key\": \"18e63413ba6e2f4d81ec74e7660d93d9\", \"tools_names\": [\"duckduckgosearch\"]}]'}, events=[]), Span(span_id='4e38a79b9b05eb45', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id=None, name='crewai.task_execute_core', start_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 27904), end_time=datetime.datetime(2025, 6, 8, 17, 18, 29, 381414), attributes={'telemetry.sdk.name': 'openlit', 'gen_ai.system': 'crewai', 'gen_ai.operation.name': 'agent', 'gen_ai.endpoint': 'crewai.task_execute_core', 'service.name': 'default', 'deployment.environment': 'default', 'gen_ai.agent.task.id': '70d9cbd8-2c44-4585-8407-5dc3a341e11f', 'gen_ai.agent.task': 'What is AWS Bedrock?', 'gen_ai.agent.expected_output': 'Compose a short summary that includes the answer.', 'gen_ai.agent.actual_output': 'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.', 'gen_ai.agent.human_input': 'False', 'gen_ai.agent.task_associations': \"{'Writer'}\"}, events=[]), Span(span_id='eb4b714c2b5de034', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id='4e38a79b9b05eb45', name='Task Created', start_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 27989), end_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 28029), attributes={'crew_key': 'a7f38a97312c2a08d7161334f446c413', 'crew_id': 'dbb3f4b1-952a-41d9-8579-65b940961723', 'task_key': 'a4e196e286182fc8683d3e8a3ea41110', 'task_id': '70d9cbd8-2c44-4585-8407-5dc3a341e11f', 'crew_fingerprint': '701b4b29-f5d1-498e-95c7-7afccf4877cb', 'task_fingerprint': '9c3c5c11-9bb8-460e-b493-3bb6ed3e22e7', 'task_fingerprint_created_at': '2025-06-08T17:18:27.024547', 'agent_fingerprint': '411151d5-c538-49e1-9d2a-13698d9fa7c2'}, events=[]), Span(span_id='cf884b2d17cb1cee', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id='4e38a79b9b05eb45', name='crewai.agent_execute_task', start_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 30751), end_time=datetime.datetime(2025, 6, 8, 17, 18, 29, 380706), attributes={'telemetry.sdk.name': 'openlit', 'gen_ai.system': 'crewai', 'gen_ai.operation.name': 'agent', 'gen_ai.endpoint': 'crewai.agent_execute_task', 'service.name': 'default', 'deployment.environment': 'default', 'gen_ai.agent.id': '6cf70835-7ba4-4304-8f19-8b478c4d0147', 'gen_ai.agent.role': 'Writer', 'gen_ai.agent.goal': 'You make GenAI concepts understandable for newbies exploring GenAI on AWS', 'gen_ai.agent.context': \"You're an expert in writing crisp summaries about GenAI on AWS.\", 'gen_ai.agent.enable_cache': 'True', 'gen_ai.agent.allow_delegation': 'False', 'gen_ai.agent.allow_code_execution': 'False', 'gen_ai.agent.max_retry_limit': '2', 'gen_ai.agent.tools': '[{\"name\": \"DuckDuckGoSearch\", \"description\": \"Tool Name: DuckDuckGoSearch\\\\nTool Arguments: {\\'search_query\\': {\\'description\\': None, \\'type\\': \\'str\\'}}\\\\nTool Description: Search the web for information on a given topic\"}]', 'gen_ai.agent.tool_results': '[{\\'result\\': \\'[{\\\\\\'title\\\\\\': \\\\\\'Amazon Bedrock\\\\\\', \\\\\\'href\\\\\\': \\\\\\'https://aws.amazon.com/bedrock/\\\\\\', \\\\\\'body\\\\\\': \\\\\\'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models\\\\\\'}, {\\\\\\'title\\\\\\': \\\\\\'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com\\\\\\', \\\\\\'href\\\\\\': \\\\\\'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\\\\', \\\\\\'body\\\\\\': \\\\\\'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.\\\\\\'}, {\\\\\\'title\\\\\\': \\\\\\'What is Amazon Bedrock? - GeeksforGeeks\\\\\\', \\\\\\'href\\\\\\': \\\\\\'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/\\\\\\', \\\\\\'body\\\\\\': \"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we\\\\\\'ll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\"}, {\\\\\\'title\\\\\\': \\\\\\'Amazon Bedrock Documentation\\\\\\', \\\\\\'href\\\\\\': \\\\\\'https://docs.aws.amazon.com/bedrock/\\\\\\', \\\\\\'body\\\\\\': \\\\\\'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.\\\\\\'}, {\\\\\\'title\\\\\\': \\\\\\'Amazon Bedrock Documentation - aws.amazon.com\\\\\\', \\\\\\'href\\\\\\': \\\\\\'https://aws.amazon.com/documentation-overview/bedrock/\\\\\\', \\\\\\'body\\\\\\': \\\\\\'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.\\\\\\'}]\\', \\'tool_name\\': \\'DuckDuckGoSearch\\', \\'tool_args\\': {\\'search_query\\': \\'AWS Bedrock\\'}}]'}, events=[]), Span(span_id='90ae256532724579', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id='cf884b2d17cb1cee', name='chat bedrock/us.amazon.nova-pro-v1:0', start_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 31697), end_time=datetime.datetime(2025, 6, 8, 17, 18, 27, 673708), attributes={'telemetry.sdk.name': 'openlit', 'gen_ai.operation.name': 'chat', 'gen_ai.system': 'litellm', 'gen_ai.request.model': 'bedrock/us.amazon.nova-pro-v1:0', 'gen_ai.request.seed': '', 'server.port': 'NOT_FOUND', 'gen_ai.request.frequency_penalty': 0.0, 'gen_ai.request.max_tokens': 4096, 'gen_ai.request.presence_penalty': 0.0, 'gen_ai.request.stop_sequences': '[\"\\\\nObservation:\"]', 'gen_ai.request.temperature': 0.7, 'gen_ai.request.top_p': 1.0, 'gen_ai.response.id': 'chatcmpl-756b4211-10ab-41c1-84d4-93ffdc57cbf4', 'gen_ai.response.model': 'us.amazon.nova-pro-v1:0', 'gen_ai.usage.input_tokens': 305, 'gen_ai.usage.output_tokens': 20, 'server.address': 'NOT_FOUND', 'gen_ai.request.service_tier': 'auto', 'gen_ai.response.system_fingerprint': 'None', 'deployment.environment': 'default', 'service.name': 'default', 'gen_ai.request.user': '', 'gen_ai.request.is_stream': False, 'gen_ai.usage.total_tokens': 325, 'gen_ai.usage.cost': 0, 'gen_ai.server.time_to_first_token': 0.641761064529419, 'gen_ai.sdk.version': '1.68.0', 'gen_ai.response.finish_reasons': '[\"stop\"]', 'gen_ai.output.type': 'text'}, events=[SpanEvent(name='gen_ai.content.prompt', timestamp=datetime.datetime(2025, 6, 8, 17, 18, 27, 673517), attributes={'gen_ai.prompt': 'system: You are Writer. You\\'re an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {\\'search_query\\': {\\'description\\': None, \\'type\\': \\'str\\'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:'}), SpanEvent(name='gen_ai.content.completion', timestamp=datetime.datetime(2025, 6, 8, 17, 18, 27, 673529), attributes={'gen_ai.completion': 'Action: DuckDuckGoSearch\\nAction Input: {\"search_query\": \"AWS Bedrock\"}'})]), Span(span_id='280d88e85cec8f10', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id='cf884b2d17cb1cee', name='Tool Usage', start_time=datetime.datetime(2025, 6, 8, 17, 18, 28, 353627), end_time=datetime.datetime(2025, 6, 8, 17, 18, 28, 354369), attributes={'crewai_version': '0.126.0', 'tool_name': 'DuckDuckGoSearch', 'attempts': 1}, events=[]), Span(span_id='501d95d80618db17', trace_id='5a9b0d264fd003657e4d334e410601a7', parent_id='cf884b2d17cb1cee', name='chat bedrock/us.amazon.nova-pro-v1:0', start_time=datetime.datetime(2025, 6, 8, 17, 18, 28, 355018), end_time=datetime.datetime(2025, 6, 8, 17, 18, 29, 379326), attributes={'telemetry.sdk.name': 'openlit', 'gen_ai.operation.name': 'chat', 'gen_ai.system': 'litellm', 'gen_ai.request.model': 'bedrock/us.amazon.nova-pro-v1:0', 'gen_ai.request.seed': '', 'server.port': 'NOT_FOUND', 'gen_ai.request.frequency_penalty': 0.0, 'gen_ai.request.max_tokens': 4096, 'gen_ai.request.presence_penalty': 0.0, 'gen_ai.request.stop_sequences': '[\"\\\\nObservation:\"]', 'gen_ai.request.temperature': 0.7, 'gen_ai.request.top_p': 1.0, 'gen_ai.response.id': 'chatcmpl-3cfc7e80-adc2-4df1-9679-74f712d36b96', 'gen_ai.response.model': 'us.amazon.nova-pro-v1:0', 'gen_ai.usage.input_tokens': 1269, 'gen_ai.usage.output_tokens': 107, 'server.address': 'NOT_FOUND', 'gen_ai.request.service_tier': 'auto', 'gen_ai.response.system_fingerprint': 'None', 'deployment.environment': 'default', 'service.name': 'default', 'gen_ai.request.user': '', 'gen_ai.request.is_stream': False, 'gen_ai.usage.total_tokens': 1376, 'gen_ai.usage.cost': 0, 'gen_ai.server.time_to_first_token': 1.0240778923034668, 'gen_ai.sdk.version': '1.68.0', 'gen_ai.response.finish_reasons': '[\"stop\"]', 'gen_ai.output.type': 'text'}, events=[SpanEvent(name='gen_ai.content.prompt', timestamp=datetime.datetime(2025, 6, 8, 17, 18, 29, 379199), attributes={'gen_ai.prompt': 'system: You are Writer. You\\'re an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {\\'search_query\\': {\\'description\\': None, \\'type\\': \\'str\\'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\\nassistant: [{\\'title\\': \\'Amazon Bedrock\\', \\'href\\': \\'https://aws.amazon.com/bedrock/\\', \\'body\\': \\'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models\\'}, {\\'title\\': \\'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com\\', \\'href\\': \\'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\', \\'body\\': \\'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.\\'}, {\\'title\\': \\'What is Amazon Bedrock? - GeeksforGeeks\\', \\'href\\': \\'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/\\', \\'body\\': \"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we\\'ll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\"}, {\\'title\\': \\'Amazon Bedrock Documentation\\', \\'href\\': \\'https://docs.aws.amazon.com/bedrock/\\', \\'body\\': \\'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.\\'}, {\\'title\\': \\'Amazon Bedrock Documentation - aws.amazon.com\\', \\'href\\': \\'https://aws.amazon.com/documentation-overview/bedrock/\\', \\'body\\': \\'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.\\'}]\\nassistant: Action: DuckDuckGoSearch\\nAction Input: {\"search_query\": \"AWS Bedrock\"}\\nObservation: [{\\'title\\': \\'Amazon Bedrock\\', \\'href\\': \\'https://aws.amazon.com/bedrock/\\', \\'body\\': \\'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models\\'}, {\\'title\\': \\'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com\\', \\'href\\': \\'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\', \\'body\\': \\'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.\\'}, {\\'title\\': \\'What is Amazon Bedrock? - GeeksforGeeks\\', \\'href\\': \\'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/\\', \\'body\\': \"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we\\'ll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\"}, {\\'title\\': \\'Amazon Bedrock Documentation\\', \\'href\\': \\'https://docs.aws.amazon.com/bedrock/\\', \\'body\\': \\'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data.\\'}, {\\'title\\': \\'Amazon Bedrock Documentation - aws.amazon.com\\', \\'href\\': \\'https://aws.amazon.com/documentation-overview/bedrock/\\', \\'body\\': \\'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.\\'}]'}), SpanEvent(name='gen_ai.content.completion', timestamp=datetime.datetime(2025, 6, 8, 17, 18, 29, 379212), attributes={'gen_ai.completion': '\\n\\nThought: I now know the final answer\\nFinal Answer: Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.'})])])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trajectory = create_trajectory(spans)\n",
        "trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flotorch_eval.agent_eval.core.evaluator import Evaluator\n",
        "from flotorch_eval.agent_eval.metrics.langchain_metrics import (\n",
        "    TrajectoryEvalWithLLMMetric,\n",
        "    TrajectoryEvalWithoutLLMMetric,\n",
        ")\n",
        "from flotorch_eval.agent_eval.metrics.ragas_metrics import (\n",
        "    AgentGoalAccuracyMetric,\n",
        "    ToolCallAccuracyMetric,\n",
        ")\n",
        "from flotorch_eval.agent_eval.metrics.base import MetricConfig\n",
        "\n",
        "evaluator = Evaluator([\n",
        "    ToolCallAccuracyMetric(),\n",
        "    AgentGoalAccuracyMetric(llm=llm,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_answer\": \"mazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"  # optional\n",
        "        }\n",
        "    )),\n",
        "    TrajectoryEvalWithLLMMetric(llm = bedrock_model,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_outputs\": [\n",
        "    {\"role\": \"user\", \"content\": \"What is AWS Bedrock?\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"To compose a poem about Amazon Bedrock, I first need to gather information about what Amazon Bedrock is. I will use the available tool to search for this information.\",\n",
        "        \"tool_calls\": [\n",
        "            {\n",
        "                \"function\": {\n",
        "                    \"name\": \"Search the web for information on a given topic\",\n",
        "                    \"arguments\": \"{\\\"search_query\\\": \\\"Amazon Bedrock\\\"}\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    {\"role\": \"tool\", \"content\": \"{\\\"searchParameters\\\": {\\\"q\\\": \\\"Amazon Bedrock\\\", \\\"type\\\": \\\"search\\\", \\\"num\\\": 5, \\\"engine\\\": \\\"google\\\"}, \\\"organic\\\": [{\\\"title\\\": \\\"Amazon Bedrock - Generative AI - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/\\\", \\\"snippet\\\": \\\"Amazon Bedrock Data Automation streamlines the generation of valuable insights from unstructured multimodal content such as documents, images, audio, and videos ...\\\", \\\"position\\\": 1, \\\"sitelinks\\\": [{\\\"title\\\": \\\"Amazon Bedrock\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Pricing\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/pricing/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Documentation\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock FAQs\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/faqs/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Agents\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/agents/\\\"}]}, {\\\"title\\\": \\\"Getting Started with Amazon Bedrock - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/awstv/watch/6ff4cd6fa97/\\\", \\\"snippet\\\": \\\"So check the region that you're currently in, make sure it's a region that's supported by Bedrock. Then I'm gonna scroll to the bottom of this ...\\\", \\\"position\\\": 2}], \\\"relatedSearches\\\": [{\\\"query\\\": \\\"Amazon Bedrock pricing\\\"}, {\\\"query\\\": \\\"Amazon Bedrock documentation\\\"}, {\\\"query\\\": \\\"Amazon Bedrock Claude\\\"}, {\\\"query\\\": \\\"Amazon Bedrock logo\\\"}, {\\\"query\\\": \\\"Amazon Bedrock DeepSeek\\\"}], \\\"credits\\\": 1}\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Based on the observation, I have learned that mazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"}\n",
        "]\n",
        "        }\n",
        "    ))])\n",
        "\n",
        "# Evaluate trajectory\n",
        "results = await evaluator.evaluate(trajectory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
