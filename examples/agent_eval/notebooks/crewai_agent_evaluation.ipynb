{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Building & Evaluating Complex Agents with `strands` and `flotorch-eval`\n",
        "\n",
        "In this notebook, we'll walk through a complete example of evaluating agents using the **`flotorch-eval`** package across key metrics. These metrics help assess both agent quality and system performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç Evaluation Metrics\n",
        "\n",
        "- **`AgentGoalAccuracyMetric`**  \n",
        "  Evaluates whether the agent successfully understood and achieved the user's goal.  \n",
        "  - **Binary** (1 = goal achieved, 0 = not achieved)\n",
        "\n",
        "- **`ToolCallAccuracyMetric`**  \n",
        "  Measures the correctness of tool usage by the agent‚Äîi.e., whether the agent called the right tools to complete a task.  \n",
        "  - **Binary** (1 = relevant tools invoked, 0 = relevant tools not invoked)\n",
        "\n",
        "- **`TrajectoryEvalWithLLM`**  \n",
        "  Evaluates whether the trajectory (based on OpenTelemetry spans) is meaningful, either with or without a reference trajectory.  \n",
        "  - **Binary** (1 = meaningful, 0 = invalid)\n",
        "\n",
        "- **`LatencyMetric`**  \n",
        "  Measures agent latency‚Äîhow fast the agent responds or completes tasks.  \n",
        "  \n",
        "\n",
        "- **`UsageMetric`**  \n",
        "  Evaluates the cost-efficiency of the agent in terms of compute, tokens, or other usage dimensions.  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setup and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install numpy pandas langchain-aws ragas openlit -q\n",
        "!pip install flotorch-eval crewai duckduckgo-search uv -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Configure Tracing with OpenLit\n",
        "To evaluate our agent, we first need to record what it does. We'll use OpenLit to automatically create a detailed trace of the agent's execution, including every LLM call and tool usage.\n",
        "\n",
        "We'll store these traces in memory for easy access during the evaluation phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding of current TracerProvider is not allowed\n",
            "OpenLIT metrics setup failed. Metrics will not be available: 'NoneType' object has no attribute 'create_histogram'\n"
          ]
        }
      ],
      "source": [
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter\n",
        "\n",
        "# Create an in-memory span exporter\n",
        "memory_exporter = InMemorySpanExporter()\n",
        "span_processor = SimpleSpanProcessor(memory_exporter)\n",
        "\n",
        "# Set up the tracer provider and add the span processor\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(span_processor)\n",
        "trace.set_tracer_provider(tracer_provider)\n",
        "\n",
        "# Initialize OpenLit - this will automatically instrument CrewAI when it's imported\n",
        "import openlit\n",
        "openlit.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))\n",
        "\n",
        "# Import required libraries\n",
        "from typing import List\n",
        "import asyncio\n",
        "\n",
        "from crewai.tools import tool\n",
        "from crewai import LLM\n",
        "from crewai import Agent, Task, Crew\n",
        "from duckduckgo_search import DDGS\n",
        "from langchain_aws import ChatBedrockConverse\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "from flotorch_eval.agent_eval.core.evaluator import Evaluator\n",
        "from flotorch_eval.agent_eval.metrics.base import BaseMetric\n",
        "from flotorch_eval.agent_eval.metrics.langchain_metrics import (\n",
        "    TrajectoryEvalWithLLMMetric,\n",
        "    TrajectoryEvalWithoutLLMMetric)\n",
        "from flotorch_eval.agent_eval.metrics.ragas_metrics import (\n",
        "    AgentGoalAccuracyMetric,\n",
        "    ToolCallAccuracyMetric,)\n",
        "from flotorch_eval.agent_eval.metrics.latency_metrics import LatencyMetric\n",
        "from flotorch_eval.agent_eval.metrics.base import MetricConfig\n",
        "from flotorch_eval.agent_eval.metrics.usage_metrics import UsageMetric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Setup\n",
        "Before we build the agent, let's set up the components needed for its evaluation.\n",
        "\n",
        "##### Configure the LLM Judge\n",
        "Some of our metrics require an LLM to \"judge\" the agent's output for quality and correctness.  \n",
        "For this, we're choosing **`Amazon Nova Micro`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "region = \"us-west-2\"\n",
        "bedrock_model = ChatBedrockConverse(\n",
        "    region_name=region,\n",
        "    endpoint_url=f\"https://bedrock-runtime.us-west-2.amazonaws.com\",\n",
        "    model_id=\"us.amazon.nova-micro-v1:0\"\n",
        ")\n",
        "\n",
        "llm_judge = LangchainLLMWrapper(bedrock_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define the Evaluation Logic\n",
        "This helper function orchestrates the evaluation process. It takes the captured traces (spans) and the evaluation metrics, runs the evaluator, and displays the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluation_utils import create_trajectory, initialize_evaluator, display_evaluation_results\n",
        "\n",
        "async def evaluate_agent(metrics: List[BaseMetric], spans: List):\n",
        "    \"\"\"\n",
        "    Runs an agent with a given prompt, captures its trace, evaluates it,\n",
        "    and displays the results.\n",
        "\n",
        "    Args:\n",
        "        agent: The agent to be evaluated.\n",
        "        prompt: The input prompt for the agent.\n",
        "        metrics: A list of configured metrics for evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Capture and convert the trace\n",
        "    if not spans:\n",
        "        print(\"\\nEvaluation failed: No spans were provided.\")\n",
        "        return\n",
        "\n",
        "    trajectory = create_trajectory(spans)\n",
        "\n",
        "    # 2. Initialize and run the evaluator\n",
        "    evaluator = initialize_evaluator(metrics)\n",
        "    print(\"\\n--- Running Evaluation ---\")\n",
        "    results = await evaluator.evaluate(trajectory)\n",
        "\n",
        "    # 3. Display results\n",
        "    print(\"\\n--- Evaluation Scores ---\")\n",
        "    display_evaluation_results(results)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use case: AWS Tech Agent\n",
        "\n",
        "Now, let's build, run, and evaluate our agent.\n",
        "\n",
        "#### Build the Agent\n",
        "We'll define the agent's tools, its LLM, its role, and the task it needs to perform.\n",
        "\n",
        "**`Tools`**: It will have a DuckDuckGoSearch tool to look up information, Salesforce API to get data  \n",
        "**`LLM`**: It will be powered by the amazon.nova-pro-v1:0 model on Amazon Bedrock.  \n",
        "**`Role`**: Its purpose is to be a Writer that simplifies GenAI concepts on AWS for beginner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the tools that will be used by the agents\n",
        "@tool('DuckDuckGoSearch')\n",
        "def search_tool(search_query: str):\n",
        "    \"\"\"Search the web for information on a given topic\"\"\"\n",
        "    return DDGS().text(search_query, max_results=5)\n",
        "\n",
        "@tool('SalesforceIntegration')\n",
        "def salesforce_tool(soql_query: str):\n",
        "    \"\"\"Call Salesforce API to get data\"\"\"\n",
        "    return \"Salesforce Integration\"\n",
        "\n",
        "# setup the model that is going to be used with the model\n",
        "model = LLM(\n",
        "    # model=\"sagemaker/INSERT ENDPOINT NAME\",\n",
        "    model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
        "    temperature=0.7, max_tokens=4*1024,\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "        role=\"Writer\",\n",
        "        goal=\"You make GenAI concepts understandable for newbies exploring GenAI on AWS\",\n",
        "        backstory=\"You're an expert in writing crisp summaries about GenAI on AWS.\",\n",
        "        tools=[search_tool],\n",
        "        llm=model\n",
        "    )\n",
        "\n",
        "task = Task(description=(\"What is {topic}?\"),\n",
        "            expected_output=(\"Compose a short summary that includes the answer.\"),\n",
        "            agent=writer)\n",
        "\n",
        "crew = Crew(\n",
        "  agents=[writer],\n",
        "  tasks=[task],\n",
        "  share_crew=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run the Agent\n",
        "Let's kickoff the crew to perform its task with a topic. OpenLit will automatically capture the entire execution in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"name\": \"Crew Created\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0x4dedcba592986524ecb8da57a4691802\",\n",
            "        \"span_id\": \"0x6f62dd8b44322025\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-06-13T13:20:22.014930Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:22.017066Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crewai_version\": \"0.130.0\",\n",
            "        \"python_version\": \"3.10.12\",\n",
            "        \"crew_key\": \"a7f38a97312c2a08d7161334f446c413\",\n",
            "        \"crew_id\": \"cc181df4-8fda-4109-82a6-d1be90ba8d5d\",\n",
            "        \"crew_process\": \"sequential\",\n",
            "        \"crew_memory\": false,\n",
            "        \"crew_number_of_tasks\": 1,\n",
            "        \"crew_number_of_agents\": 1,\n",
            "        \"crew_fingerprint\": \"efa53190-6e84-4e3c-8bed-4a9e06ae57f1\",\n",
            "        \"crew_fingerprint_created_at\": \"2025-06-13T18:50:20.330560\",\n",
            "        \"crew_agents\": \"[{\\\"key\\\": \\\"18e63413ba6e2f4d81ec74e7660d93d9\\\", \\\"id\\\": \\\"e4a3c5b6-2268-4d82-9f7c-1e12c0c4c301\\\", \\\"role\\\": \\\"Writer\\\", \\\"verbose?\\\": false, \\\"max_iter\\\": 25, \\\"max_rpm\\\": null, \\\"function_calling_llm\\\": \\\"\\\", \\\"llm\\\": \\\"bedrock/us.amazon.nova-pro-v1:0\\\", \\\"delegation_enabled?\\\": false, \\\"allow_code_execution?\\\": false, \\\"max_retry_limit\\\": 2, \\\"tools_names\\\": [\\\"duckduckgosearch\\\"]}]\",\n",
            "        \"crew_tasks\": \"[{\\\"key\\\": \\\"a4e196e286182fc8683d3e8a3ea41110\\\", \\\"id\\\": \\\"3c549fa6-4309-4b35-9912-a3b668ef8d8a\\\", \\\"async_execution?\\\": false, \\\"human_input?\\\": false, \\\"agent_role\\\": \\\"Writer\\\", \\\"agent_key\\\": \\\"18e63413ba6e2f4d81ec74e7660d93d9\\\", \\\"tools_names\\\": [\\\"duckduckgosearch\\\"]}]\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"Task Created\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xb86160b5be9d4582\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xf2bfcc9617ad6f43\",\n",
            "    \"start_time\": \"2025-06-13T13:20:22.026141Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:22.026247Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crew_key\": \"a7f38a97312c2a08d7161334f446c413\",\n",
            "        \"crew_id\": \"cc181df4-8fda-4109-82a6-d1be90ba8d5d\",\n",
            "        \"task_key\": \"a4e196e286182fc8683d3e8a3ea41110\",\n",
            "        \"task_id\": \"3c549fa6-4309-4b35-9912-a3b668ef8d8a\",\n",
            "        \"crew_fingerprint\": \"efa53190-6e84-4e3c-8bed-4a9e06ae57f1\",\n",
            "        \"task_fingerprint\": \"4eaa0078-86eb-467d-b473-a7b20e971770\",\n",
            "        \"task_fingerprint_created_at\": \"2025-06-13T18:50:20.330436\",\n",
            "        \"agent_fingerprint\": \"0c425b86-8b76-4440-ab84-f1e482c058f0\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"chat bedrock/us.amazon.nova-pro-v1:0\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xfe5905e41f0f1713\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xe886629f03099ffb\",\n",
            "    \"start_time\": \"2025-06-13T13:20:22.028482Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:23.250345Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.operation.name\": \"chat\",\n",
            "        \"gen_ai.system\": \"litellm\",\n",
            "        \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.request.seed\": \"\",\n",
            "        \"server.port\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.frequency_penalty\": 0.0,\n",
            "        \"gen_ai.request.max_tokens\": 4096,\n",
            "        \"gen_ai.request.presence_penalty\": 0.0,\n",
            "        \"gen_ai.request.stop_sequences\": [\n",
            "            \"\\nObservation:\"\n",
            "        ],\n",
            "        \"gen_ai.request.temperature\": 0.7,\n",
            "        \"gen_ai.request.top_p\": 1.0,\n",
            "        \"gen_ai.response.id\": \"chatcmpl-1f7dbc40-5013-41e3-bda6-a0a8dc87b4cb\",\n",
            "        \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.usage.input_tokens\": 305,\n",
            "        \"gen_ai.usage.output_tokens\": 20,\n",
            "        \"server.address\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.service_tier\": \"auto\",\n",
            "        \"gen_ai.response.system_fingerprint\": \"None\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"gen_ai.request.user\": \"\",\n",
            "        \"gen_ai.request.is_stream\": false,\n",
            "        \"gen_ai.usage.total_tokens\": 325,\n",
            "        \"gen_ai.usage.cost\": 0,\n",
            "        \"gen_ai.server.time_to_first_token\": 1.2215211391448975,\n",
            "        \"gen_ai.sdk.version\": \"1.72.0\",\n",
            "        \"gen_ai.response.finish_reasons\": [\n",
            "            \"stop\"\n",
            "        ],\n",
            "        \"gen_ai.output.type\": \"text\"\n",
            "    },\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.prompt\",\n",
            "            \"timestamp\": \"2025-06-13T13:20:23.250117Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.prompt\": \"system: You are Writer. You're an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it's written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \\\" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\"\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.completion\",\n",
            "            \"timestamp\": \"2025-06-13T13:20:23.250135Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.completion\": \"Action: DuckDuckGoSearch\\nAction Input: {\\\"search_query\\\": \\\"AWS Bedrock\\\"}\"\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"Tool Usage\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xa59aa6ed4b9d97e9\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.INTERNAL\",\n",
            "    \"parent_id\": \"0xe886629f03099ffb\",\n",
            "    \"start_time\": \"2025-06-13T13:20:24.234060Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:24.234959Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"crewai_version\": \"0.130.0\",\n",
            "        \"tool_name\": \"DuckDuckGoSearch\",\n",
            "        \"attempts\": 1\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"chat bedrock/us.amazon.nova-pro-v1:0\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xc3a5c8dbf221f6f3\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xe886629f03099ffb\",\n",
            "    \"start_time\": \"2025-06-13T13:20:24.236093Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:25.768224Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.operation.name\": \"chat\",\n",
            "        \"gen_ai.system\": \"litellm\",\n",
            "        \"gen_ai.request.model\": \"bedrock/us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.request.seed\": \"\",\n",
            "        \"server.port\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.frequency_penalty\": 0.0,\n",
            "        \"gen_ai.request.max_tokens\": 4096,\n",
            "        \"gen_ai.request.presence_penalty\": 0.0,\n",
            "        \"gen_ai.request.stop_sequences\": [\n",
            "            \"\\nObservation:\"\n",
            "        ],\n",
            "        \"gen_ai.request.temperature\": 0.7,\n",
            "        \"gen_ai.request.top_p\": 1.0,\n",
            "        \"gen_ai.response.id\": \"chatcmpl-e9437612-4a8d-4154-8671-14f50469071e\",\n",
            "        \"gen_ai.response.model\": \"us.amazon.nova-pro-v1:0\",\n",
            "        \"gen_ai.usage.input_tokens\": 821,\n",
            "        \"gen_ai.usage.output_tokens\": 115,\n",
            "        \"server.address\": \"NOT_FOUND\",\n",
            "        \"gen_ai.request.service_tier\": \"auto\",\n",
            "        \"gen_ai.response.system_fingerprint\": \"None\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"gen_ai.request.user\": \"\",\n",
            "        \"gen_ai.request.is_stream\": false,\n",
            "        \"gen_ai.usage.total_tokens\": 936,\n",
            "        \"gen_ai.usage.cost\": 0,\n",
            "        \"gen_ai.server.time_to_first_token\": 1.5318405628204346,\n",
            "        \"gen_ai.sdk.version\": \"1.72.0\",\n",
            "        \"gen_ai.response.finish_reasons\": [\n",
            "            \"stop\"\n",
            "        ],\n",
            "        \"gen_ai.output.type\": \"text\"\n",
            "    },\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.prompt\",\n",
            "            \"timestamp\": \"2025-06-13T13:20:25.768040Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.prompt\": \"system: You are Writer. You're an expert in writing crisp summaries about GenAI on AWS.\\nYour personal goal is: You make GenAI concepts understandable for newbies exploring GenAI on AWS\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: DuckDuckGoSearch\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\nTool Description: Search the web for information on a given topic\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [DuckDuckGoSearch], just the name, exactly as it's written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \\\" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```\\nuser: \\nCurrent Task: What is AWS Bedrock?\\n\\nThis is the expected criteria for your final answer: Compose a short summary that includes the answer.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:\\nassistant: Action: DuckDuckGoSearch\\nAction Input: {\\\"search_query\\\": \\\"AWS Bedrock\\\"}\\nObservation: [{'title': 'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com', 'href': 'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html', 'body': 'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.'}, {'title': 'Build Generative AI Applications with Foundation Models - Amazon ...', 'href': 'https://aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models. Get started with Amazon Bedrock. Try free demo ...'}, {'title': 'What is Amazon Bedrock? - GeeksforGeeks', 'href': 'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/', 'body': \\\"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we'll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\\\"}, {'title': 'Amazon Bedrock Documentation', 'href': 'https://docs.aws.amazon.com/bedrock/', 'body': 'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; PDF; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data. ...'}, {'title': 'Amazon Bedrock Documentation - aws.amazon.com', 'href': 'https://aws.amazon.com/documentation-overview/bedrock/', 'body': 'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.'}]\"\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"gen_ai.content.completion\",\n",
            "            \"timestamp\": \"2025-06-13T13:20:25.768057Z\",\n",
            "            \"attributes\": {\n",
            "                \"gen_ai.completion\": \"\\n\\nThought: I now know the final answer\\nFinal Answer: Amazon Bedrock is a fully managed service that makes it easy to build and scale generative AI applications with foundation models from third-party providers and Amazon. It provides a unified API to access and customize these models, allowing developers to build applications with security, privacy, and responsible AI practices. Amazon Bedrock also enables the use of Retrieval Augmented Generation (RAG) with your data to improve model responses and allows for the orchestration of multistep tasks, tracing of reasoning, and application of guardrails for responsible AI.\"\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"crewai.agent_execute_task\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xe886629f03099ffb\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": \"0xf2bfcc9617ad6f43\",\n",
            "    \"start_time\": \"2025-06-13T13:20:22.027308Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:25.770565Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.system\": \"crewai\",\n",
            "        \"gen_ai.operation.name\": \"agent\",\n",
            "        \"gen_ai.endpoint\": \"crewai.agent_execute_task\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"gen_ai.agent.id\": \"e4a3c5b6-2268-4d82-9f7c-1e12c0c4c301\",\n",
            "        \"gen_ai.agent.role\": \"Writer\",\n",
            "        \"gen_ai.agent.goal\": \"You make GenAI concepts understandable for newbies exploring GenAI on AWS\",\n",
            "        \"gen_ai.agent.context\": \"You're an expert in writing crisp summaries about GenAI on AWS.\",\n",
            "        \"gen_ai.agent.enable_cache\": \"True\",\n",
            "        \"gen_ai.agent.allow_delegation\": \"False\",\n",
            "        \"gen_ai.agent.allow_code_execution\": \"False\",\n",
            "        \"gen_ai.agent.max_retry_limit\": \"2\",\n",
            "        \"gen_ai.agent.tools\": \"[{\\\"name\\\": \\\"DuckDuckGoSearch\\\", \\\"description\\\": \\\"Tool Name: DuckDuckGoSearch\\\\nTool Arguments: {'search_query': {'description': None, 'type': 'str'}}\\\\nTool Description: Search the web for information on a given topic\\\"}]\",\n",
            "        \"gen_ai.agent.tool_results\": \"[{'result': '[{\\\\'title\\\\': \\\\'What is Amazon Bedrock? - Amazon Bedrock - docs.aws.amazon.com\\\\', \\\\'href\\\\': \\\\'https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock lets you use and customize high-performing AI models from leading companies and Amazon through a unified API. You can build generative AI applications with security, privacy, and responsible AI using AWS tools and data sources.\\\\'}, {\\\\'title\\\\': \\\\'Build Generative AI Applications with Foundation Models - Amazon ...\\\\', \\\\'href\\\\': \\\\'https://aws.amazon.com/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock. The easiest way to build and scale generative AI applications with foundation models. Get started with Amazon Bedrock. Try free demo ...\\\\'}, {\\\\'title\\\\': \\\\'What is Amazon Bedrock? - GeeksforGeeks\\\\', \\\\'href\\\\': \\\\'https://www.geeksforgeeks.org/amazon-bedrock-aws-bedrock/\\\\', \\\\'body\\\\': \\\"Amazon Bedrock is a fully managed service from AWS that lets you build AI-Powered applications quickly and easily without managing servers or training AI models yourself. In the given below article, we\\\\'ll explain how Amazon Bedrock works, its benefits, and how businesses can use it to bring AI into their products and services. AWS Bedrock\\\"}, {\\\\'title\\\\': \\\\'Amazon Bedrock Documentation\\\\', \\\\'href\\\\': \\\\'https://docs.aws.amazon.com/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. ... Connect Amazon Bedrock features and other AWS services to create generative AI workflows. HTML; PDF; Knowledge bases. Improve model responses by using Retrieval Augmented Generation (RAG) with your data. ...\\\\'}, {\\\\'title\\\\': \\\\'Amazon Bedrock Documentation - aws.amazon.com\\\\', \\\\'href\\\\': \\\\'https://aws.amazon.com/documentation-overview/bedrock/\\\\', \\\\'body\\\\': \\\\'Amazon Bedrock lets you build generative AI applications with a choice of foundation models (FMs) from different AI companies, using a single API. You can customize FMs with your data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI.\\\\'}]', 'tool_name': 'DuckDuckGoSearch', 'tool_args': {'search_query': 'AWS Bedrock'}}]\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"name\": \"crewai.task_execute_core\",\n",
            "    \"context\": {\n",
            "        \"trace_id\": \"0xb9e5a71a7e7ec8f37bf8149c36bb6263\",\n",
            "        \"span_id\": \"0xf2bfcc9617ad6f43\",\n",
            "        \"trace_state\": \"[]\"\n",
            "    },\n",
            "    \"kind\": \"SpanKind.CLIENT\",\n",
            "    \"parent_id\": null,\n",
            "    \"start_time\": \"2025-06-13T13:20:22.025980Z\",\n",
            "    \"end_time\": \"2025-06-13T13:20:25.771375Z\",\n",
            "    \"status\": {\n",
            "        \"status_code\": \"OK\"\n",
            "    },\n",
            "    \"attributes\": {\n",
            "        \"telemetry.sdk.name\": \"openlit\",\n",
            "        \"gen_ai.system\": \"crewai\",\n",
            "        \"gen_ai.operation.name\": \"agent\",\n",
            "        \"gen_ai.endpoint\": \"crewai.task_execute_core\",\n",
            "        \"service.name\": \"default\",\n",
            "        \"deployment.environment\": \"default\",\n",
            "        \"gen_ai.agent.task.id\": \"3c549fa6-4309-4b35-9912-a3b668ef8d8a\",\n",
            "        \"gen_ai.agent.task\": \"What is AWS Bedrock?\",\n",
            "        \"gen_ai.agent.expected_output\": \"Compose a short summary that includes the answer.\",\n",
            "        \"gen_ai.agent.actual_output\": \"Amazon Bedrock is a fully managed service that makes it easy to build and scale generative AI applications with foundation models from third-party providers and Amazon. It provides a unified API to access and customize these models, allowing developers to build applications with security, privacy, and responsible AI practices. Amazon Bedrock also enables the use of Retrieval Augmented Generation (RAG) with your data to improve model responses and allows for the orchestration of multistep tasks, tracing of reasoning, and application of guardrails for responsible AI.\",\n",
            "        \"gen_ai.agent.human_input\": \"False\",\n",
            "        \"gen_ai.agent.task_associations\": \"{'Writer'}\"\n",
            "    },\n",
            "    \"events\": [],\n",
            "    \"links\": [],\n",
            "    \"resource\": {\n",
            "        \"attributes\": {\n",
            "            \"telemetry.sdk.language\": \"python\",\n",
            "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
            "            \"telemetry.sdk.version\": \"1.34.1\",\n",
            "            \"service.name\": \"unknown_service\"\n",
            "        },\n",
            "        \"schema_url\": \"\"\n",
            "    }\n",
            "}\n",
            "Amazon Bedrock is a fully managed service that makes it easy to build and scale generative AI applications with foundation models from third-party providers and Amazon. It provides a unified API to access and customize these models, allowing developers to build applications with security, privacy, and responsible AI practices. Amazon Bedrock also enables the use of Retrieval Augmented Generation (RAG) with your data to improve model responses and allows for the orchestration of multistep tasks, tracing of reasoning, and application of guardrails for responsible AI.\n"
          ]
        }
      ],
      "source": [
        "result = crew.kickoff({\"topic\": \"AWS Bedrock\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define Ground Truth for Evaluation\n",
        "Evaluate the agent using reference data, including the expected agent response and trajectory. Use an LLM to compare the agent's output against this reference to assess performance.\n",
        "\n",
        "**`A reference answer`**: The ideal final output we expect.  \n",
        "**`A reference trajectory`**: The ideal sequence of thoughts and tool calls the agent should have taken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "REFERENCE_FINAL_ANSWER=\"Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"\n",
        "\n",
        "REFERENCE_TRAJECTORY_OUTPUTS = [\n",
        "                {\"role\": \"user\", \"content\": \"What is AWS Bedrock?\"},\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": \"To compose a poem about Amazon Bedrock, I first need to gather information about what Amazon Bedrock is. I will use the available tool to search for this information.\",\n",
        "                    \"tool_calls\": [\n",
        "                        {\n",
        "                            \"function\": {\n",
        "                                \"name\": \"Search the web for information on a given topic\",\n",
        "                                \"arguments\": \"{\\\"search_query\\\": \\\"Amazon Bedrock\\\"}\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                {\"role\": \"tool\", \"content\": \"{\\\"searchParameters\\\": {\\\"q\\\": \\\"Amazon Bedrock\\\", \\\"type\\\": \\\"search\\\", \\\"num\\\": 5, \\\"engine\\\": \\\"google\\\"}, \\\"organic\\\": [{\\\"title\\\": \\\"Amazon Bedrock - Generative AI - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/\\\", \\\"snippet\\\": \\\"Amazon Bedrock Data Automation streamlines the generation of valuable insights from unstructured multimodal content such as documents, images, audio, and videos ...\\\", \\\"position\\\": 1, \\\"sitelinks\\\": [{\\\"title\\\": \\\"Amazon Bedrock\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Pricing\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/pricing/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Documentation\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock FAQs\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/faqs/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Agents\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/agents/\\\"}]}, {\\\"title\\\": \\\"Getting Started with Amazon Bedrock - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/awstv/watch/6ff4cd6fa97/\\\", \\\"snippet\\\": \\\"So check the region that you're currently in, make sure it's a region that's supported by Bedrock. Then I'm gonna scroll to the bottom of this ...\\\", \\\"position\\\": 2}], \\\"relatedSearches\\\": [{\\\"query\\\": \\\"Amazon Bedrock pricing\\\"}, {\\\"query\\\": \\\"Amazon Bedrock documentation\\\"}, {\\\"query\\\": \\\"Amazon Bedrock Claude\\\"}, {\\\"query\\\": \\\"Amazon Bedrock logo\\\"}, {\\\"query\\\": \\\"Amazon Bedrock DeepSeek\\\"}], \\\"credits\\\": 1}\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"Based on the observation, I have learned that mazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"}\n",
        "            ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run the Evaluation\n",
        "Finally, we retrieve the captured traces (spans), configure our evaluation metrics, and run the evaluate_agent function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of spans: 0\n"
          ]
        }
      ],
      "source": [
        "spans = memory_exporter.get_finished_spans()\n",
        "print(\"Number of spans:\", len(spans))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = [\n",
        "    ToolCallAccuracyMetric(),\n",
        "    AgentGoalAccuracyMetric(llm=llm_judge,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_answer\": REFERENCE_FINAL_ANSWER\n",
        "            }\n",
        "        )),\n",
        "    TrajectoryEvalWithLLMMetric(llm = bedrock_model,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_outputs\": REFERENCE_TRAJECTORY_OUTPUTS\n",
        "        }\n",
        "    )),\n",
        "    UsageMetric(config=MetricConfig(\n",
        "        metric_params={\"aws_region\": \"us-west-2\"}\n",
        "    )),\n",
        "    LatencyMetric()\n",
        "    ]\n",
        "\n",
        "# Evaluate trajectory\n",
        "async def evaluate_dataframe_agent():\n",
        "    return await evaluate_agent(metrics, spans)\n",
        "\n",
        "# Execute the evaluation\n",
        "results = asyncio.run(evaluate_dataframe_agent())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
